---
---

@inproceedings{tjuatja2021transferOCR,
    abbr = {WiNLP}
    title={{Explorations in Transfer Learning for OCR Post-Correction}},
    author={Tjuatja, Lindia and Rijhwani, Shruti and Neubig, Graham},
    booktitle={Widening NLP Workshop-Accepted Papers,},
    year={2021},
    pdf={WiNLP_Explorations_Transfer_Learning_OCR.pdf}
}

@inproceedings{tjuatja-etal-2023-syntax,
    abbr = {*SEM},
    title = "Syntax and Semantics Meet in the {``}Middle{''}: Probing the Syntax-Semantics Interface of {LM}s Through Agentivity",
    author = "Tjuatja, Lindia  and
      Liu, Emmy  and
      Levin, Lori  and
      Neubig, Graham",
    editor = "Palmer, Alexis  and
      Camacho-collados, Jose",
    booktitle = "Proceedings of the 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = {https://aclanthology.org/2023.starsem-1.14},
    code={https://github.com/lindiatjuatja/lm_sem},
    doi = "10.18653/v1/2023.starsem-1.14",
    pages = "149--164",
}

@inproceedings{he2023sigmorefun,
  abbr = {SIGMORPHON},
  title={SigMoreFun submission to the SIGMORPHON shared task on interlinear glossing},
  author={He, Taiqi* and Tjuatja, Lindia* and Robinson, Nathaniel and Watanabe, Shinji and Mortensen, David R and Neubig, Graham and Levin, Lori},
  booktitle={Proceedings of the 20th SIGMORPHON workshop on Computational Research in Phonetics, Phonology, and Morphology},
  year={2023},
  url = {https://aclanthology.org/2023.sigmorphon-1.22/},
}

@inproceedings{ginn-etal-2024-glosslm,
  abbr = {EMNLP},
  title = "{G}loss{LM}: A Massively Multilingual Corpus and Pretrained Model for Interlinear Glossed Text",
  author = "Ginn, Michael*  and
    Tjuatja, Lindia*  and
    He, Taiqi  and
    Rice, Enora  and
    Neubig, Graham  and
    Palmer, Alexis  and
    Levin, Lori",
  editor = "Al-Onaizan, Yaser  and
    Bansal, Mohit  and
    Chen, Yun-Nung",
  booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
  month = nov,
  year = "2024",
  address = "Miami, Florida, USA",
  publisher = "Association for Computational Linguistics",
  url = {https://aclanthology.org/2024.emnlp-main.683},
  code = {https://github.com/foltaProject/glosslm},
  pages = "12267--12286",
  abstract = "Language documentation projects often involve the creation of annotated text in a format such as interlinear glossed text (IGT), which captures fine-grained morphosyntactic analyses in a morpheme-by-morpheme format. However, there are few existing resources providing large amounts of standardized, easily accessible IGT data, limiting their applicability to linguistic research, and making it difficult to use such data in NLP modeling. We compile the largest existing corpus of IGT data from a variety of sources, covering over 450k examples across 1.8k languages, to enable research on crosslingual transfer and IGT generation. We normalize much of our data to follow a standard set of labels across languages.Furthermore, we explore the task of automatically generating IGT in order to aid documentation projects. As many languages lack sufficient monolingual data, we pretrain a large multilingual model on our corpus. We demonstrate the utility of this model by finetuning it on monolingual corpora, outperforming SOTA models by up to 6.6{\%}. Our pretrained model and dataset are available on Hugging Face: https://huggingface.co/collections/lecslab/glosslm-66da150854209e910113dd87",
}

@article{10.1162/tacl_a_00685,
  abbr = {TACL},
  author = {Tjuatja, Lindia* and Chen, Valerie* and Wu, Tongshuang and Talwalkwar, Ameet and Neubig, Graham},
  title = "{Do LLMs Exhibit Human-like Response Biases? A Case Study in Survey Design}",
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {12},
  pages = {1011-1026},
  year = {2024},
  month = {09},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00685},
  url = {https://doi.org/10.1162/tacl\_a\_00685},
  code = {https://github.com/lindiatjuatja/BiasMonkey},
  eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00685/2468689/tacl\_a\_00685.pdf},
}
